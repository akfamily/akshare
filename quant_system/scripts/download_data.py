#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†å²æ•°æ®ä¸‹è½½è„šæœ¬
ä¸€æ¬¡æ€§ä¸‹è½½æ‰€éœ€çš„å†å²æ•°æ®ï¼Œä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
"""

import sys
import os
from datetime import datetime, timedelta
import pickle
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from utils.logger import logger
from data.fetcher.akshare_api import AKShareAPI


class DataDownloader:
    """æ•°æ®ä¸‹è½½å™¨"""

    def __init__(self, cache_dir='data/cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.api = AKShareAPI()
        self.logger = logger

    def download_all(self, years=3):
        """
        ä¸‹è½½æ‰€æœ‰éœ€è¦çš„å†å²æ•°æ®

        Args:
            years: ä¸‹è½½æœ€è¿‘å‡ å¹´çš„æ•°æ®
        """
        print("\n" + "="*60)
        print("å¼€å§‹ä¸‹è½½å†å²æ•°æ®...")
        print(f"æ•°æ®å¹´é™: æœ€è¿‘{years}å¹´")
        print("="*60 + "\n")

        # 1. ä¸‹è½½å®è§‚æ•°æ®
        self.logger.info("1/5 ä¸‹è½½å®è§‚æ•°æ®...")
        print("ğŸ“Š [1/5] ä¸‹è½½å®è§‚æ•°æ®ï¼ˆGDPã€CPIã€PPIã€PMIç­‰ï¼‰...")
        macro_data = self._download_macro_data()
        self._save_cache('macro_data', macro_data)
        print(f"  âœ“ å®è§‚æ•°æ®ä¸‹è½½å®Œæˆï¼Œå…±{sum(len(v) for v in macro_data.values())}æ¡è®°å½•\n")

        # 2. ä¸‹è½½å¸‚åœºæ•°æ®
        self.logger.info("2/5 ä¸‹è½½å¸‚åœºæ•°æ®...")
        print("ğŸ“ˆ [2/5] ä¸‹è½½å¸‚åœºæ•°æ®ï¼ˆæŒ‡æ•°ã€è¡Œæƒ…ï¼‰...")
        market_data = self._download_market_data(years)
        self._save_cache('market_data', market_data)
        print(f"  âœ“ å¸‚åœºæ•°æ®ä¸‹è½½å®Œæˆ\n")

        # 3. ä¸‹è½½è¡Œä¸šæ•°æ®
        self.logger.info("3/5 ä¸‹è½½è¡Œä¸šæ•°æ®...")
        print("ğŸ­ [3/5] ä¸‹è½½è¡Œä¸šåˆ†ç±»æ•°æ®...")
        industry_data = self._download_industry_data()
        self._save_cache('industry_data', industry_data)
        print(f"  âœ“ è¡Œä¸šæ•°æ®ä¸‹è½½å®Œæˆï¼Œå…±{len(industry_data.get('industry_list', []))}ä¸ªè¡Œä¸š\n")

        # 4. ä¸‹è½½ä¼°å€¼æ•°æ®
        self.logger.info("4/5 ä¸‹è½½ä¼°å€¼æ•°æ®...")
        print("ğŸ’° [4/5] ä¸‹è½½ä¼°å€¼æ•°æ®ï¼ˆPEã€PBï¼‰...")
        valuation_data = self._download_valuation_data()
        self._save_cache('valuation_data', valuation_data)
        print(f"  âœ“ ä¼°å€¼æ•°æ®ä¸‹è½½å®Œæˆ\n")

        # 5. ä¸‹è½½èµ„é‡‘æ•°æ®
        self.logger.info("5/5 ä¸‹è½½èµ„é‡‘æ•°æ®...")
        print("ğŸ’µ [5/5] ä¸‹è½½èµ„é‡‘æµå‘æ•°æ®...")
        fund_data = self._download_fund_data()
        self._save_cache('fund_data', fund_data)
        print(f"  âœ“ èµ„é‡‘æ•°æ®ä¸‹è½½å®Œæˆ\n")

        print("="*60)
        print("ğŸ‰ æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆï¼")
        print(f"ç¼“å­˜ä½ç½®: {self.cache_dir.absolute()}")
        print("="*60 + "\n")

        # ä¿å­˜ä¸‹è½½æ—¶é—´
        self._save_cache('last_download', {
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'years': years
        })

    def _download_macro_data(self):
        """ä¸‹è½½å®è§‚æ•°æ®"""
        macro_data = {}

        try:
            # GDP
            macro_data['gdp'] = self.api.get_macro_china_gdp()

            # CPI
            macro_data['cpi'] = self.api.get_macro_china_cpi()

            # PPI
            macro_data['ppi'] = self.api.get_macro_china_ppi()

            # PMI
            macro_data['pmi'] = self.api.get_macro_china_pmi()

            # M2
            macro_data['m2'] = self.api.get_macro_china_m2()

            # ç¤¾è
            macro_data['social_financing'] = self.api.get_macro_china_social_financing()

        except Exception as e:
            self.logger.error(f"ä¸‹è½½å®è§‚æ•°æ®å¤±è´¥: {e}")
            # è¿”å›æ¨¡æ‹Ÿæ•°æ®
            macro_data = self._get_mock_macro_data()

        return macro_data

    def _download_market_data(self, years):
        """ä¸‹è½½å¸‚åœºæ•°æ®"""
        market_data = {}

        end_date = datetime.now()
        start_date = end_date - timedelta(days=365 * years)

        try:
            # æ²ªæ·±300æŒ‡æ•°
            market_data['hs300'] = self.api.get_index_zh_a_hist(
                '000300',
                start_date=start_date.strftime('%Y%m%d'),
                end_date=end_date.strftime('%Y%m%d')
            )

            # ä¸Šè¯æŒ‡æ•°
            market_data['sh000001'] = self.api.get_index_zh_a_hist(
                '000001',
                start_date=start_date.strftime('%Y%m%d'),
                end_date=end_date.strftime('%Y%m%d')
            )

            # Aè‚¡åˆ—è¡¨
            market_data['stock_list'] = self.api.get_stock_zh_a_spot()

        except Exception as e:
            self.logger.error(f"ä¸‹è½½å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            market_data = {}

        return market_data

    def _download_industry_data(self):
        """ä¸‹è½½è¡Œä¸šæ•°æ®"""
        industry_data = {}

        try:
            # è¡Œä¸šåˆ†ç±»
            industry_data['industry_list'] = self.api.get_stock_board_industry_name_em()

        except Exception as e:
            self.logger.error(f"ä¸‹è½½è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
            industry_data = {}

        return industry_data

    def _download_valuation_data(self):
        """ä¸‹è½½ä¼°å€¼æ•°æ®"""
        valuation_data = {}

        try:
            # å…¨A PE PB
            valuation_data['all_a'] = self.api.get_stock_a_ttm_lyr()

        except Exception as e:
            self.logger.error(f"ä¸‹è½½ä¼°å€¼æ•°æ®å¤±è´¥: {e}")
            valuation_data = {}

        return valuation_data

    def _download_fund_data(self):
        """ä¸‹è½½èµ„é‡‘æ•°æ®"""
        fund_data = {}

        try:
            # åŒ—å‘èµ„é‡‘
            fund_data['north_flow'] = self.api.get_stock_em_hsgt_north_net_flow_in()

        except Exception as e:
            self.logger.error(f"ä¸‹è½½èµ„é‡‘æ•°æ®å¤±è´¥: {e}")
            fund_data = {}

        return fund_data

    def _save_cache(self, name, data):
        """ä¿å­˜ç¼“å­˜"""
        cache_file = self.cache_dir / f'{name}.pkl'
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
            self.logger.info(f"ç¼“å­˜ä¿å­˜æˆåŠŸ: {cache_file}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def load_cache(self, name):
        """åŠ è½½ç¼“å­˜"""
        cache_file = self.cache_dir / f'{name}.pkl'
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                self.logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        return None

    def check_cache_age(self):
        """æ£€æŸ¥ç¼“å­˜æ–°é²œåº¦"""
        last_download = self.load_cache('last_download')
        if last_download:
            download_date = datetime.strptime(last_download['date'], '%Y-%m-%d %H:%M:%S')
            age_days = (datetime.now() - download_date).days

            print(f"ç¼“å­˜ä¿¡æ¯:")
            print(f"  ä¸‹è½½æ—¥æœŸ: {last_download['date']}")
            print(f"  æ•°æ®å¹´é™: {last_download['years']}å¹´")
            print(f"  å·²è¿‡å»: {age_days}å¤©")

            if age_days > 7:
                print(f"  âš ï¸  å»ºè®®é‡æ–°ä¸‹è½½ï¼ˆæ•°æ®è¾ƒæ—§ï¼‰")
                return False
            else:
                print(f"  âœ“ ç¼“å­˜ä»ç„¶æ–°é²œ")
                return True
        else:
            print("æœªæ‰¾åˆ°ç¼“å­˜ï¼Œè¯·å…ˆè¿è¡Œä¸‹è½½")
            return False

    def _get_mock_macro_data(self):
        """è·å–æ¨¡æ‹Ÿå®è§‚æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        import pandas as pd
        import numpy as np

        dates = pd.date_range(end=datetime.now(), periods=36, freq='M')

        return {
            'gdp': pd.DataFrame({
                'æ—¥æœŸ': dates[::3],  # å­£åº¦æ•°æ®
                'GDP': np.random.uniform(70000, 90000, 12)
            }),
            'cpi': pd.DataFrame({
                'æ—¥æœŸ': dates,
                'CPI': np.random.uniform(98, 103, 36)
            }),
            'ppi': pd.DataFrame({
                'æ—¥æœŸ': dates,
                'PPI': np.random.uniform(95, 107, 36)
            }),
            'pmi': pd.DataFrame({
                'æ—¥æœŸ': dates,
                'PMI': np.random.uniform(48, 52, 36)
            })
        }


def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸš€ Aè‚¡é‡åŒ–ç³»ç»Ÿ - æ•°æ®ä¸‹è½½å·¥å…·\n")

    downloader = DataDownloader()

    # æ£€æŸ¥ç°æœ‰ç¼“å­˜
    print("æ£€æŸ¥ç°æœ‰ç¼“å­˜...")
    if downloader.check_cache_age():
        response = input("\næ˜¯å¦é‡æ–°ä¸‹è½½ï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            print("å–æ¶ˆä¸‹è½½")
            return

    # å¼€å§‹ä¸‹è½½
    print()
    years = input("è¯·è¾“å…¥è¦ä¸‹è½½çš„å†å²æ•°æ®å¹´é™ï¼ˆå»ºè®®3å¹´ï¼‰[é»˜è®¤3]: ").strip()
    years = int(years) if years else 3

    downloader.download_all(years=years)

    print("æç¤ºï¼šä¸‹æ¬¡è¿è¡Œç³»ç»Ÿæ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œé€Ÿåº¦æ›´å¿«ï¼\n")


if __name__ == '__main__':
    main()
